# 多线程与高并发

### 1、volatile关键字的作用

- 1、防止JVM优化自动重排序（参考单例类分配内存-初始化-赋值 变 分配 - 赋值 -初始化）
- 2、线程间变量可见性
- 3、保证单次读写的原子性

### 2、AQS基本队列的原理

AQS（AbstractQueuedSynchronizer）是Java中的一个并发工具类，它提供了一个基本的队列机制，用于实现锁、信号量、倒计时器等同步工具。

AQS的基本队列是指一种先进先出的双向链表，用于存储等待获取锁的线程。这个队列由AQS内部维护，主要包括两个指针：head和tail。head指向队列中的第一个节点，tail指向队列中的最后一个节点。当一个线程获取锁失败时，它会被加入到这个队列的末尾，等待其他线程释放锁后再次尝试获取锁。

AQS的基本队列的操作包括入队（enqueuing）和出队（dequeuing）。当一个线程需要获取锁时，它会尝试入队；当一个线程释放锁时，它会尝试出队。由于AQS的基本队列是双向链表，因此入队和出队的操作非常高效，时间复杂度为O(1)。

AQS的基本队列是实现锁、信号量、倒计时器等同步工具的核心，这些同步工具都是基于AQS的基本队列进行实现的。在Java的并发编程中，AQS的基本队列是一个非常重要的概念，理解它可以帮助我们更好地理解Java中的并发工具和同步机制。

### 3、CAS

CAS是Compare And Swap（比较并交换）的缩写，是一种用于实现多线程同步的原子操作。

CAS操作包括三个参数：内存地址V、期望值A和新值B。CAS会先读取内存地址V中的值，如果该值等于期望值A，则将内存地址V中的值更新为新值B；否则不做任何操作。CAS操作是原子性的，即多个线程同时进行CAS操作时，只有一个线程能成功执行操作，其它线程需要重新尝试。

CAS的主要优点是比较高的并发性和非阻塞性，不需要使用锁来实现同步，因此避免了锁的开销和死锁等问题。它在一些多线程并发编程的场景中非常有用，例如计数器、队列等数据结构的实现。

在Java中，CAS操作是通过java.util.concurrent包中的AtomicInteger等原子类实现的，这些类提供了一些方法来实现CAS操作，如compareAndSet()等。通过使用原子类和CAS操作，Java提供了一种非常高效的多线程同步机制，避免了传统锁机制的开销和问题。

### 4、ABA问题

ABA问题是一种在多线程编程中可能出现的问题，它指的是在一个线程修改某个共享变量时，其他线程可能会对该变量进行干扰，导致出现意外的结果。

具体来说，ABA问题发生在以下场景中：假设线程A读取共享变量的值为A，接着线程B将共享变量的值修改为B，然后又将共享变量的值修改为A，此时线程A再次读取共享变量的值也是A，因此线程A无法感知到变量的中间状态（即从A变成B再变回A），可能会对后续的操作造成错误的判断和结果。

解决ABA问题的常见方法是通过添加版本号或时间戳等机制来对共享变量的状态进行跟踪，这样即使共享变量的值从A变成B再变回A，版本号或时间戳也会随之更新，从而避免出现ABA问题。另外，Java中的一些同步工具（如CAS和AtomicStampedReference）也提供了一些原子操作，可以用于解决ABA问题。

### 5、ConcurrenthashMap如何保证线程安全？

1. 分段锁：将整个数据结构分成多个segment（默认为16），每个segment维护一个独立的哈希表，每个segment内部实现了自己的锁机制，不同segment之间互不干扰，不同线程访问不同segment的时候可以并发进行，从而提高了并发度；
2. volatile关键字：在Java内存模型中，通过volatile关键字可以保证可见性和有序性，因此ConcurrentHashMap内部使用了volatile关键字来保证数据的可见性和有序性，防止线程之间发生数据竞争；
3. CAS（Compare-And-Swap）操作：ConcurrentHashMap内部使用了CAS操作来保证数据的一致性。在多线程并发情况下，当多个线程同时修改同一个数据时，只有一个线程能够成功修改，其他线程需要不断重试直到成功，从而保证数据的一致性。

通过这些并发控制技术，**`ConcurrentHashMap`**能够高效地支持多线程并发访问，而不需要像**`Hashtable`**一样使用全局锁来保证线程安全，从而在高并发场景下具有更好的性能表现。

### 6、使用**CountDownLatch时有任务失败了怎么办**

?

如果在 **`CountDownLatch`** 中某个任务失败了，即某个任务的线程抛出了异常，可以考虑将该异常保存下来，并在其他线程中检查它。一种实现方式是使用一个 **`AtomicReference`\**对象保存异常，每个线程检查该对象是否为\**`null`**，如果不为 **`null`**，则说明其他线程中有一个任务失败了，需要将异常重新抛出。

### 7、Java线程池的参数

Java中的线程池有以下几个参数：

1. `corePoolSize`：线程池的核心线程数，即线程池维护的最小线程数；
2. `maximumPoolSize`：线程池的最大线程数，即线程池允许的最大线程数；
3. `keepAliveTime`：线程池中线程空闲后的存活时间；
4. `unit`：`keepAliveTime` 的时间单位；
5. `workQueue`：用于保存等待执行的任务的阻塞队列；
6. `threadFactory`：用于创建线程的工厂类；
7. `handler`：拒绝策略，用于当任务添加到线程池中被拒绝时的处理方式。

其中，`corePoolSize`、`maximumPoolSize`、`keepAliveTime`、`unit` 和 `workQueue` 是线程池的核心参数，`threadFactory` 和 `handler` 是可选参数。

- `corePoolSize` 和 `maximumPoolSize` 一般需要根据业务场景和系统资源限制来确定，可以使用 `Runtime.getRuntime().availableProcessors()` 获取当前系统的 CPU 核心数作为默认值。
- `keepAliveTime` 和 `unit` 决定了线程池中的非核心线程空闲后的存活时间。
- `workQueue` 决定了线程池中等待执行的任务的队列类型和大小。
- `threadFactory` 可以指定线程创建的方式，例如使用自定义线程名称、线程优先级等。
- `handler` 可以指定线程池中的任务被拒绝后的处理方式，例如抛出异常、直接丢弃等。常用的拒绝策略有 `AbortPolicy`、`CallerRunsPolicy`、`DiscardPolicy` 和 `DiscardOldestPolicy`。

### 8、线程池有哪些拒绝策略

Java中的线程池有以下四种拒绝策略：

1. CallerRunsPolicy（调用者运行策略）：该策略下，线程池会直接在execute方法的调用线程中执行该任务。
2. AbortPolicy（中止策略）：该策略下，线程池会抛出RejectedExecutionException异常来拒绝新任务的提交。
3. DiscardPolicy（抛弃策略）：该策略下，线程池会默默地丢弃无法处理的任务，不会有任何异常抛出。
4. DiscardOldestPolicy（抛弃旧任务策略）：该策略下，线程池会丢弃队列中最老的任务，尝试重新提交当前任务。

### 9、线程池的拒绝策略的应用场景

这些拒绝策略的应用场景如下：

1. AbortPolicy适用于任务量比较小，但是突然间会出现大量任务的情况。
2. CallerRunsPolicy适用于任务处理能力比较强，可以在短时间内处理完任务，但是突然间出现大量任务的情况。
3. DiscardPolicy适用于对任务处理结果不敏感，可以直接忽略任务。
4. DiscardOldestPolicy适用于任务量比较大，但是任务处理能力比较弱，无法同时处理所有任务，需要优先处理最新提交的任务。

### 10、Synchronized和ReentrantLock的底层区别和底层实现

Synchronized和ReentrantLock都是Java中用于实现锁的机制，实现线程同步的关键字和类。它们都可以用于实现线程之间的互斥和协作，从而保证程序的正确性和可靠性。

Synchronized是Java语言中内置的关键字，是最常用的实现锁机制的方法，它是基于JVM实现的，可以实现互斥锁和条件锁。在使用Synchronized时，锁的获取和释放都是由JVM自动完成的，因此它比较简单，容易使用。但是，它有一个缺点，即只能实现非公平锁。

ReentrantLock是Java中的一个类，是基于AQS（AbstractQueuedSynchronizer）实现的。它提供了比Synchronized更高级别的功能，如可重入锁、可中断锁、公平锁和多条件变量等。它的实现比Synchronized复杂，但是它可以提供更多的灵活性和可扩展性，同时可以实现公平锁和非公平锁。

在底层实现上，Synchronized是基于Java对象头中的mark word实现的。它的原理是在对象头中存储一个锁标志位，当线程获取锁时，会将该标志位置为1，表示当前对象已被锁定；当线程释放锁时，将该标志位重新设置为0，表示当前对象未被锁定。在Synchronized中，锁的获取和释放都是由JVM自动完成的，因此使用起来非常简单。

ReentrantLock则是基于AQS实现的，它在内部维护了一个FIFO的等待队列，用于存储等待锁的线程。当线程获取锁失败时，会将其加入到等待队列中，并进行自旋等待或者挂起等待；当锁释放时，会从等待队列中取出一个线程进行唤醒。在ReentrantLock中，锁的获取和释放需要显式地调用lock和unlock方法，因此使用起来相对Synchronized更加复杂，但是它提供了更多的功能和更好的可扩展性。

### 11、`volatile`关键字的原理

`volatile`关键字是Java中的一个关键字，用于修饰变量。它的主要作用是保证变量的可见性和禁止指令重排序优化。

在Java中，每个线程都有自己的工作内存，工作内存中保存了该线程使用到的变量的主内存副本拷贝。当线程使用变量时，会将主内存中的变量值拷贝到自己的工作内存中，然后对变量进行操作。操作完成后，再将变量值刷新回主内存中。这样，每个线程都有自己的工作内存，这样就可以保证线程之间的数据相互独立，不会相互影响。

在多线程环境下，当多个线程同时操作一个变量时，如果没有使用`volatile`关键字，那么每个线程都会从主内存中拷贝一份变量到自己的工作内存中，然后对变量进行操作。操作完成后，再将变量值刷新回主内存中。这样，每个线程都会操作自己工作内存中的变量，而不会操作主内存中的变量。这样就会导致线程之间的数据不一致的问题。

使用`volatile`关键字可以解决这个问题。当变量被`volatile`修饰时，线程在操作变量时，会将变量值刷新回主内存中，这样就保证了线程之间的数据一致性。

在Java中，对于使用了volatile关键字的变量，在进行写操作时会在代码中插入一个StoreStore屏障，该屏障会强制将本地内存中的变量值刷新到主内存中，同时会使其他线程中的缓存失效。在进行读操作时会在代码中插入一个LoadLoad和一个LoadStore屏障，LoadLoad屏障保证了本地内存中读取到的变量值是最新的，而LoadStore屏障保证了在读操作之前所有的写操作都已经刷新到了主内存中，从而保证了读操作的可见性。

### 12、偏向锁

Java中的偏向锁是一种优化的锁机制，主要用于减少无竞争同步的开销。偏向锁的核心思想是，如果一个锁总是被同一个线程所请求，那么该锁就会偏向于这个线程，让它能够更快地获得锁。偏向锁的运行过程大致分为以下几个步骤：

1. **无锁状态：**当一个对象刚被创建时，它处于无锁状态。

2. **偏向锁状态：**当一个线程第一次请求这个对象的锁时，JVM会将该对象头部的偏向锁标志位设置为1，同时还会将请求锁的线程ID记录到对象头中。此后，当这个线程再次请求锁时，JVM会检查对象头中的线程ID是否与当前请求线程的ID相同，如果相同，则直接允许这个线程进入同步块，这就是偏向锁的主要优化。

3. **轻量级锁状态：**如果一个其他的线程请求这个偏向锁，JVM首先会暂停持有偏向锁的线程，然后检查持有偏向锁的线程是否处于活动状态。如果持有偏向锁的线程不处于活动状态，或者持有偏向锁的线程并没有对这个锁进行锁定，那么JVM会将偏向锁升级为轻量级锁，否则，JVM会将这个偏向锁膨胀为重量级锁。

4. **重量级锁状态：**在轻量级锁状态下，如果还有其他线程请求这个锁，那么轻量级锁就会膨胀为重量级锁。在重量级锁状态下，未能获取锁的线程会进入阻塞状态，这是最传统也是最耗费资源的一种锁状态。

需要注意的是，偏向锁、轻量级锁和重量级锁，都是Java为了优化synchronized关键字的性能而引入的锁优化机制。他们之间的关系并非严格的升级关系，而是根据具体的竞争情况动态调整。

### 13、锁升级过程

Java 的对象在多线程竞争访问时，可以通过锁的升级来改进性能。具体来说，锁的状态从无锁状态开始，可以升级到偏向锁，再升级到轻量级锁，最后升级到重量级锁。以下是这个过程的详细解释：

1. **无锁状态**：这是新创建的对象默认的状态。

2. **偏向锁**：如果一个线程首次访问一个对象，并且没有竞争，则 JVM 会在对象头上记录这个线程的 ID，这样下次这个线程再次访问这个对象时，就无需进行任何同步操作。这就是偏向锁。偏向锁的主要目的是优化那些只有一个线程访问的情况。

3. **轻量级锁**：如果一个对象处于偏向锁状态，但是有另一个线程试图访问这个对象，那么 JVM 就需要撤销（revoke）偏向锁，然后升级到轻量级锁。如果线程竞争不激烈，而且线程间相互替换的速度不高，轻量级锁能够提高程序性能。否则，如果线程竞争非常激烈，轻量级锁就会升级为重量级锁。

4. **重量级锁**：如果一个对象处于轻量级锁状态，但轻量级锁无法满足线程间的同步需求，或者有多个线程进入了轻量级锁的自旋（尝试获取锁），那么轻量级锁就会升级为重量级锁。此时，除了拥有锁的线程，其他请求锁的线程都会被阻塞。

这个过程是为了在不同的线程竞争情况下，尽可能地提高性能。在竞争较少的情况下，通过偏向锁和轻量级锁，可以避免线程阻塞和唤醒，从而提高性能。在竞争较多的情况下，通过升级到重量级锁，可以避免大量的CPU自旋消耗。